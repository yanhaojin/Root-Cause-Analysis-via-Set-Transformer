# ============================================================
# (1) Download RE1-TT (TrainTicket) + dataset overview
# (2) 60/40 split (stratified by service+fault)
# (3) Build metric->service grouping from metric names (hierarchical service-aware)
# (4) Train Hierarchical Service-Aware Set Transformer (larger epochs)
#     - Intra-service Set Encoder: metrics -> service embedding
#     - Inter-service Set Encoder: services -> global embedding -> classify root-cause service
# (5) Evaluate Avg@5 overall + per fault type
# (6) Run BARO baseline (RobustScorer[inject]) on the SAME test split
# (7) Save CSVs + download zip
# ============================================================

!pip -q install pandas numpy tqdm scikit-learn torch

import os, re, math, random, zipfile
from pathlib import Path

import numpy as np
import pandas as pd
from tqdm.auto import tqdm
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from IPython.display import display
from google.colab import files

# -------------------------
# Global config
# -------------------------
SEED = 42

# Pre/post window (timepoints)
PRE_LEN  = 300
POST_LEN = 300

# Optional failure-time misspecification
USE_TDELTA_60 = False
TDELTA_SECONDS = 60.0

# Training (larger epochs)
EPOCHS = 1500
BATCH_TRAIN = 32
BATCH_TEST  = 32
LR = 5e-4
WD = 1e-4
METRIC_DROPOUT = 0.15   # randomly drop some metric tokens during training (helps robustness)

# -------------------------
# Reproducibility
# -------------------------
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("DEVICE:", device)

# -------------------------
# Helpers
# -------------------------
def pick_time_col(df: pd.DataFrame) -> str:
    if "time" in df.columns: return "time"
    for c in df.columns:
        if isinstance(c, str) and "time" in c.lower():
            return c
    return df.columns[0]

def norm(s: str) -> str:
    return "".join(ch.lower() for ch in str(s) if ch.isalnum())

def canonical_fault(f: str) -> str:
    s = norm(f)
    if "cpu" in s: return "CPU"
    if "mem" in s or "memory" in s: return "MEM"
    if "disk" in s or "io" in s: return "DISK"
    if "delay" in s or "latency" in s: return "DELAY"
    if "loss" in s or "packet" in s: return "LOSS"
    return str(f).upper()

def robust_iqr_1d(x: np.ndarray) -> float:
    q75 = np.nanpercentile(x, 75)
    q25 = np.nanpercentile(x, 25)
    return float(q75 - q25)

def avg_at_5_from_ranks(ranks_1based):
    ac = []
    for k in range(1, 6):
        ac.append(np.mean([1.0 if r <= k else 0.0 for r in ranks_1based]))
    return float(np.mean(ac)), ac  # Avg@5, [AC@1..AC@5]

# ------------------------------------------------------------
# (1) Download RE1-TT (TrainTicket) dataset
# ------------------------------------------------------------
URL = "https://zenodo.org/records/14590730/files/RE1-TT.zip?download=1"
ZIP_PATH = Path("/content/RE1-TT.zip")
DATA_ROOT = Path("/content/re1_tt")
EXTRACTED = DATA_ROOT / "RE1-TT"

if not EXTRACTED.exists():
    DATA_ROOT.mkdir(parents=True, exist_ok=True)
    if not ZIP_PATH.exists():
        !wget -q --show-progress -O "{ZIP_PATH}" "{URL}"
    !unzip -q "{ZIP_PATH}" -d "{DATA_ROOT}"

assert EXTRACTED.exists(), f"Expected extracted folder at: {EXTRACTED}"
print("Dataset root:", EXTRACTED)

# ------------------------------------------------------------
# (2) Build summary + dataset overview
# ------------------------------------------------------------
rows = []
feature_dims = []
obs_total = 0
int_total = 0
total_timepoints = 0

fault_groups = sorted([p for p in EXTRACTED.iterdir() if p.is_dir()])

for grp in tqdm(fault_groups, desc="Scanning groups"):
    if "_" in grp.name:
        service, fault_raw = grp.name.rsplit("_", 1)
    else:
        service, fault_raw = grp.name, "unknown"
    fault = canonical_fault(fault_raw)

    reps = sorted([p for p in grp.iterdir() if p.is_dir()])
    for rep in reps:
        csv_path = rep / "simple_data.csv"
        if not csv_path.exists():
            csv_path = rep / "data.csv"
        inj_path = rep / "inject_time.txt"
        if not csv_path.exists() or not inj_path.exists():
            continue

        inj_time = float(inj_path.read_text().strip())
        df = pd.read_csv(csv_path)
        tcol = pick_time_col(df)
        t = pd.to_numeric(df[tcol], errors="coerce").to_numpy()

        metric_cols = [c for c in df.columns if c != tcol]
        d = int(len(metric_cols))
        feature_dims.append(d)

        obs = int(np.sum(t < inj_time))
        inter = int(np.sum(t >= inj_time))
        if obs == 0 or inter == 0:
            mid = len(df) // 2
            obs, inter = mid, len(df) - mid

        obs_total += obs
        int_total += inter
        total_timepoints += int(len(df))

        rows.append({
            "case_id": f"{grp.name}/{rep.name}",
            "group": grp.name,
            "root_cause_service": service,
            "fault_type_raw": fault_raw,
            "fault_type": fault,
            "csv_file": str(csv_path),
            "inject_time": inj_time,
            "n_timepoints": int(len(df)),
            "n_metric_features": d,
            "obs_timepoints": obs,
            "inter_timepoints": inter,
        })

summary = pd.DataFrame(rows)
assert len(summary) > 0, "No cases found; check extraction."

print("\n=== TrainTicket (RE1-TT) overview ===")
print("Total cases:", len(summary))
print("Unique root-cause services:", summary["root_cause_service"].nunique())
print("Fault types:", sorted(summary["fault_type"].unique()))
print("Metric dims (min/median/max):", int(np.min(feature_dims)), int(np.median(feature_dims)), int(np.max(feature_dims)))
print("Total timepoints:", int(total_timepoints))
print("Pre-injection timepoints:", int(obs_total))
print("Post-injection timepoints:", int(int_total))

print("\nCases per fault type:")
display(summary["fault_type"].value_counts().rename_axis("fault_type").reset_index(name="n_cases"))
print("\nPreview:")
display(summary.head(6))

# ------------------------------------------------------------
# (3) 60/40 split stratified by (service, fault)
# ------------------------------------------------------------
strata = (summary["root_cause_service"].astype(str) + "___" + summary["fault_type"].astype(str)).to_numpy()
idx = np.arange(len(summary))
train_idx, test_idx = train_test_split(idx, test_size=0.40, random_state=SEED, stratify=strata)
print(f"\nSplit: train={len(train_idx)} test={len(test_idx)}")

# ------------------------------------------------------------
# (4) Tokenization: robust shift features, one token per metric
# token_dim = 10: delta/zdelta/logratio/etc.
# ------------------------------------------------------------
def case_to_tokens(csv_file: str, inject_time: float):
    df = pd.read_csv(csv_file)
    tcol = pick_time_col(df)
    t = pd.to_numeric(df[tcol], errors="coerce").to_numpy()

    metric_cols = [c for c in df.columns if c != tcol]
    Xraw = df[metric_cols].apply(pd.to_numeric, errors="coerce").ffill().bfill().fillna(0.0).to_numpy(dtype=np.float32)

    # sort by time
    order = np.argsort(np.nan_to_num(t, nan=0.0))
    t = t[order]; Xraw = Xraw[order]

    inj = float(inject_time + (TDELTA_SECONDS if USE_TDELTA_60 else 0.0))
    pre_idx = np.where(t < inj)[0]
    post_idx = np.where(t >= inj)[0]
    if len(pre_idx) == 0 or len(post_idx) == 0:
        mid = len(t)//2
        pre_idx = np.arange(0, mid)
        post_idx = np.arange(mid, len(t))

    pre_idx = pre_idx[-PRE_LEN:]
    post_idx = post_idx[:POST_LEN]

    pre = Xraw[pre_idx]
    post = Xraw[post_idx]
    eps = 1e-6

    pre_mean = np.mean(pre, axis=0)
    post_mean = np.mean(post, axis=0)
    pre_std = np.std(pre, axis=0)
    post_std = np.std(post, axis=0)
    pre_med = np.median(pre, axis=0)
    post_med = np.median(post, axis=0)

    pre_iqr = np.array([robust_iqr_1d(pre[:, j]) for j in range(pre.shape[1])], dtype=np.float32)
    post_iqr = np.array([robust_iqr_1d(post[:, j]) for j in range(post.shape[1])], dtype=np.float32)

    delta_mean = post_mean - pre_mean
    abs_delta_mean = np.abs(delta_mean)
    zdelta_mean = delta_mean / (pre_std + eps)
    log_ratio_mean = np.log((post_mean + eps) / (pre_mean + eps))
    delta_std = post_std - pre_std

    delta_med = post_med - pre_med
    delta_iqr = post_iqr - pre_iqr
    log_ratio_med = np.log((post_med + eps) / (pre_med + eps))

    X = np.stack([
        delta_mean, zdelta_mean, log_ratio_mean, delta_std,
        delta_med, delta_iqr, log_ratio_med,
        pre_iqr, post_iqr, abs_delta_mean
    ], axis=1).astype(np.float32)

    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)

    # per-case normalize across metric tokens
    mu = X.mean(axis=0, keepdims=True)
    sd = X.std(axis=0, keepdims=True) + 1e-6
    X = (X - mu) / sd
    X = np.clip(X, -8.0, 8.0).astype(np.float32)

    return X, metric_cols

# ------------------------------------------------------------
# (5) Build cases + align metric order (fixed M across cases)
# ------------------------------------------------------------
services_label = sorted(summary["root_cause_service"].unique())
svc2i = {s:i for i,s in enumerate(services_label)}
i2svc = {i:s for s,i in svc2i.items()}
num_classes = len(services_label)

cases = []
metric_cols_ref = None

for _, r in tqdm(summary.iterrows(), total=len(summary), desc="Tokenizing cases"):
    fault = canonical_fault(r["fault_type"])
    X, metric_cols = case_to_tokens(r["csv_file"], float(r["inject_time"]))

    if metric_cols_ref is None:
        metric_cols_ref = metric_cols
    else:
        if metric_cols != metric_cols_ref:
            idx_map = {c:i for i,c in enumerate(metric_cols)}
            X_aligned = np.zeros((len(metric_cols_ref), X.shape[1]), dtype=np.float32)
            for j, c in enumerate(metric_cols_ref):
                if c in idx_map:
                    X_aligned[j] = X[idx_map[c]]
            X = X_aligned
            metric_cols = metric_cols_ref

    y = svc2i[r["root_cause_service"]]
    meta = {
        "case_id": r["case_id"],
        "fault_type": fault,
        "root_cause_service": r["root_cause_service"],
        "csv_file": r["csv_file"],
    }
    cases.append((X, fault, y, meta))

M = len(metric_cols_ref)
D_in = cases[0][0].shape[1]
print(f"\nFixed metrics M={M}, token_dim={D_in}")

fault_vocab = sorted({c[1] for c in cases})
fault2i = {f:i for i,f in enumerate(fault_vocab)}
print("Fault vocab:", fault_vocab)

train_cases = [cases[i] for i in train_idx]
test_cases  = [cases[i] for i in test_idx]

# ------------------------------------------------------------
# (6) Build hierarchical metric->service groups from metric names
#     We try to extract service IDs from metric column names using regex.
#     If a metric can't be matched, it goes to group "other".
# ------------------------------------------------------------
svc_regexes = [
    re.compile(r"(ts-[a-z0-9-]+-service)", re.IGNORECASE),
    re.compile(r"(ts-[a-z0-9-]+)", re.IGNORECASE),
]

def extract_service_from_metric_name(col: str):
    s = str(col)
    best = None
    for rgx in svc_regexes:
        m = rgx.findall(s)
        if m:
            # pick the longest match in this regex
            cand = max(m, key=lambda x: len(x))
            if (best is None) or (len(cand) > len(best)):
                best = cand
    return best

# Build candidate service groups from metric cols
detected = []
for col in metric_cols_ref:
    v = extract_service_from_metric_name(col)
    if v is not None:
        detected.append(v.lower())

# Ensure label services are included even if not detected
for s in services_label:
    detected.append(str(s).lower())

detected = sorted(set(detected))
# Put label services first (helps interpretability), then the rest
label_set = set([str(s).lower() for s in services_label])
svc_groups = [s for s in detected if s in label_set] + [s for s in detected if s not in label_set]
svc_groups.append("other")
svc2g = {s:i for i,s in enumerate(svc_groups)}
S = len(svc_groups)

# Map each metric to a service group index once (fixed across all cases)
metric2group = np.zeros(M, dtype=np.int64)
for j, col in enumerate(metric_cols_ref):
    sv = extract_service_from_metric_name(col)
    if sv is None:
        metric2group[j] = svc2g["other"]
    else:
        metric2group[j] = svc2g.get(sv.lower(), svc2g["other"])

# Precompute group->metric indices
group_to_metric_idx = []
for g in range(S):
    idxs = np.where(metric2group == g)[0].tolist()
    group_to_metric_idx.append(idxs)

print(f"\nHierarchical groups S={S} (including 'other').")
print("Example groups (first 20):", svc_groups[:20])
print("Metrics in 'other':", len(group_to_metric_idx[svc2g["other"]]))

# ------------------------------------------------------------
# (7) DataLoaders (no padding needed: fixed M)
# ------------------------------------------------------------
class RCADataset(Dataset):
    def __init__(self, case_list):
        self.case_list = case_list
    def __len__(self):
        return len(self.case_list)
    def __getitem__(self, i):
        X, fault, y, meta = self.case_list[i]
        return X, fault, y, meta

def collate_fn(batch):
    Xs, faults, ys, metas = zip(*batch)
    X = torch.tensor(np.stack(Xs, axis=0), dtype=torch.float32)  # [B,M,D]
    f = torch.tensor([fault2i[z] for z in faults], dtype=torch.long)
    y = torch.tensor(ys, dtype=torch.long)
    return X, f, y, list(metas)

train_loader = DataLoader(RCADataset(train_cases), batch_size=BATCH_TRAIN, shuffle=True, collate_fn=collate_fn, num_workers=0)
test_loader  = DataLoader(RCADataset(test_cases),  batch_size=BATCH_TEST,  shuffle=False, collate_fn=collate_fn, num_workers=0)

# ------------------------------------------------------------
# (8) Hierarchical Service-Aware Set Transformer
#     - Metric projection -> metric embeddings
#     - Intra-service Set Encoder: metrics of each service -> service embedding
#     - Inter-service Set Encoder: service embeddings -> global embedding
#     - Classifier head (optionally conditioned on fault embedding)
# ------------------------------------------------------------
class SAB(nn.Module):
    def __init__(self, dim, num_heads=4, dropout=0.1, ln=True):
        super().__init__()
        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)
        self.ln0 = nn.LayerNorm(dim) if ln else None
        self.ff = nn.Sequential(
            nn.Linear(dim, dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dim, dim),
        )
        self.ln1 = nn.LayerNorm(dim) if ln else None

    def forward(self, X):
        H, _ = self.attn(X, X, X, need_weights=False)
        H = H + X
        if self.ln0 is not None:
            H = self.ln0(H)
        O = self.ff(H) + H
        if self.ln1 is not None:
            O = self.ln1(O)
        return O

class PMA(nn.Module):
    def __init__(self, dim, num_heads=4, num_seeds=1, dropout=0.1, ln=True):
        super().__init__()
        self.S = nn.Parameter(torch.randn(1, num_seeds, dim))
        self.attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)
        self.ln0 = nn.LayerNorm(dim) if ln else None

    def forward(self, X):  # X: [B,L,dim]
        B = X.size(0)
        S = self.S.repeat(B, 1, 1)
        H, _ = self.attn(S, X, X, need_weights=False)
        if self.ln0 is not None:
            H = self.ln0(H)
        return H  # [B,num_seeds,dim]

class IntraServiceEncoder(nn.Module):
    def __init__(self, dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.sab1 = SAB(dim, num_heads=num_heads, dropout=dropout)
        self.sab2 = SAB(dim, num_heads=num_heads, dropout=dropout)
        self.pma = PMA(dim, num_heads=num_heads, num_seeds=1, dropout=dropout)
        self.empty = nn.Parameter(torch.zeros(1, dim))

    def forward(self, Xs):  # Xs: [B,Ls,dim]
        if Xs is None or Xs.size(1) == 0:
            # [B,dim]
            return self.empty.repeat(Xs.size(0), 1) if Xs is not None else self.empty
        H = self.sab1(Xs)
        H = self.sab2(H)
        P = self.pma(H).squeeze(1)  # [B,dim]
        return P

class InterServiceEncoder(nn.Module):
    def __init__(self, dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.sab1 = SAB(dim, num_heads=num_heads, dropout=dropout)
        self.sab2 = SAB(dim, num_heads=num_heads, dropout=dropout)
        self.pma = PMA(dim, num_heads=num_heads, num_seeds=1, dropout=dropout)

    def forward(self, Semb):  # [B,S,dim]
        H = self.sab1(Semb)
        H = self.sab2(H)
        G = self.pma(H).squeeze(1)  # [B,dim]
        return G

class HierarchicalSetTransformer(nn.Module):
    def __init__(self, token_dim, d_model=128, num_heads=4, dropout=0.1,
                 n_faults=5, fault_emb_dim=32, n_classes=5):
        super().__init__()
        self.metric_proj = nn.Linear(token_dim, d_model)
        self.metric_drop = nn.Dropout(dropout)

        self.intra = IntraServiceEncoder(d_model, num_heads=num_heads, dropout=dropout)
        self.inter = InterServiceEncoder(d_model, num_heads=num_heads, dropout=dropout)

        self.fault_emb = nn.Embedding(n_faults, fault_emb_dim)

        self.head = nn.Sequential(
            nn.Linear(d_model + fault_emb_dim, d_model),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, n_classes)
        )

    def forward(self, X_metric, fault_ids, group_to_metric_idx, metric_dropout_p=0.0):
        # X_metric: [B,M,token_dim]
        B, M, _ = X_metric.shape
        Hm = self.metric_proj(X_metric)  # [B,M,d_model]

        if self.training and metric_dropout_p > 0:
            keep = (torch.rand(B, M, device=Hm.device) > metric_dropout_p).float().unsqueeze(-1)
            Hm = Hm * keep

        Hm = self.metric_drop(Hm)

        # Build service embeddings by grouping metrics
        Semb_list = []
        for idxs in group_to_metric_idx:
            if len(idxs) == 0:
                # create a dummy empty tensor to trigger empty-embedding
                Xs = Hm[:, :0, :]
                Semb = self.intra(Xs)
            else:
                Xs = Hm[:, idxs, :]  # [B,Ls,d_model]
                Semb = self.intra(Xs)
            Semb_list.append(Semb)

        Semb = torch.stack(Semb_list, dim=1)  # [B,S,d_model]
        G = self.inter(Semb)                  # [B,d_model]

        fe = self.fault_emb(fault_ids)        # [B,fault_emb_dim]
        logits = self.head(torch.cat([G, fe], dim=-1))
        return logits

model = HierarchicalSetTransformer(
    token_dim=D_in, d_model=128, num_heads=4, dropout=0.1,
    n_faults=len(fault_vocab), fault_emb_dim=32, n_classes=num_classes
).to(device)

opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)
criterion = nn.CrossEntropyLoss()

@torch.no_grad()
def evaluate_model(loader):
    model.eval()
    ranks_all = []
    ranks_by_fault = {f: [] for f in fault_vocab}
    per_case = []

    for X, f_id, y, metas in loader:
        X, f_id, y = X.to(device), f_id.to(device), y.to(device)
        logits = model(X, f_id, group_to_metric_idx, metric_dropout_p=0.0)
        probs = torch.softmax(logits, dim=-1)
        order = torch.argsort(probs, dim=-1, descending=True)

        for i in range(y.size(0)):
            true = int(y[i].item())
            ord_i = order[i].tolist()
            rank = ord_i.index(true) + 1
            fault = metas[i]["fault_type"]

            ranks_all.append(rank)
            ranks_by_fault[fault].append(rank)

            top5 = ord_i[:5]
            per_case.append({
                "case_id": metas[i]["case_id"],
                "fault_type": fault,
                "true_service": metas[i]["root_cause_service"],
                "pred_service": i2svc[top5[0]],
                "rank_true": rank,
                "top5_services": ",".join([i2svc[j] for j in top5]),
                "p_true": float(probs[i, true].item()),
            })

    overall_avg5, overall_ac = avg_at_5_from_ranks(ranks_all)
    by_fault_avg5 = {k: (avg_at_5_from_ranks(v)[0] if len(v) else float("nan")) for k, v in ranks_by_fault.items()}
    return overall_avg5, overall_ac, by_fault_avg5, pd.DataFrame(per_case)

# ------------------------------------------------------------
# (9) Train Hierarchical model (larger epochs)
# ------------------------------------------------------------
train_log = []
for epoch in tqdm(range(1, EPOCHS + 1), desc="Training Hierarchical ST"):
    model.train()
    total_loss, n = 0.0, 0

    for X, f_id, y, _ in train_loader:
        X, f_id, y = X.to(device), f_id.to(device), y.to(device)
        opt.zero_grad(set_to_none=True)

        logits = model(X, f_id, group_to_metric_idx, metric_dropout_p=METRIC_DROPOUT)
        loss = criterion(logits, y)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        opt.step()

        bs = y.size(0)
        total_loss += float(loss.item()) * bs
        n += bs

    overall_avg5, overall_ac, by_fault_avg5, _ = evaluate_model(test_loader)
    row = {
        "epoch": epoch,
        "train_loss": total_loss / max(n, 1),
        "Avg@5_overall": overall_avg5,
        "AC@1": overall_ac[0], "AC@3": overall_ac[2], "AC@5": overall_ac[4],
    }
    for f in ["CPU","MEM","DISK","DELAY","LOSS"]:
        if f in by_fault_avg5:
            row[f"Avg@5_{f}"] = by_fault_avg5[f]
    train_log.append(row)

overall_avg5_st, overall_ac_st, by_fault_st, pred_df_st = evaluate_model(test_loader)
log_df_st = pd.DataFrame(train_log)

summary_df_st = pd.DataFrame([{
    "method": "HierarchicalServiceAwareSetTransformer",
    "epochs": EPOCHS,
    "window_pre": PRE_LEN,
    "window_post": POST_LEN,
    "tDelta60": USE_TDELTA_60,
    "metric_dropout": METRIC_DROPOUT,
    "n_groups": S,
    "Avg@5_overall": overall_avg5_st,
    "AC@1": overall_ac_st[0], "AC@2": overall_ac_st[1], "AC@3": overall_ac_st[2], "AC@4": overall_ac_st[3], "AC@5": overall_ac_st[4],
    **{f"Avg@5_{k}": by_fault_st.get(k, float("nan")) for k in ["CPU","MEM","DISK","DELAY","LOSS"]}
}])

print("\n=== Hierarchical Set Transformer test summary ===")
print(summary_df_st.T)

# ------------------------------------------------------------
# (10) BARO baseline: RobustScorer[inject] on SAME test split
# ------------------------------------------------------------
known_services = sorted(summary["root_cause_service"].unique(), key=lambda s: -len(norm(s)))
known_services_norm = [(s, norm(s)) for s in known_services]

def metric_to_service(metric_name: str) -> str:
    m = norm(metric_name)
    for svc, svc_n in known_services_norm:
        if svc_n and (svc_n in m):
            return svc
    raw = str(metric_name)
    for delim in ["|", "/", ":", ";", ".", " "]:
        raw = raw.replace(delim, "_")
    parts = [p for p in raw.replace("-", "_").split("_") if p]
    return parts[0] if parts else "unknown"

def baro_rank_services(csv_file: str, inject_time: float, true_service: str,
                       pre_len: int = 300, post_len: int = 300):
    df = pd.read_csv(csv_file)
    tcol = pick_time_col(df)
    t = pd.to_numeric(df[tcol], errors="coerce").to_numpy()
    metric_cols = [c for c in df.columns if c != tcol]
    X = df[metric_cols].apply(pd.to_numeric, errors="coerce").ffill().bfill().fillna(0.0).to_numpy()

    order = np.argsort(np.nan_to_num(t, nan=0.0))
    t = t[order]; X = X[order]

    inj = float(inject_time)  # BARO "inject" setting
    pre_idx = np.where(t < inj)[0]
    post_idx = np.where(t >= inj)[0]
    if len(pre_idx) == 0 or len(post_idx) == 0:
        mid = len(t)//2
        pre_idx = np.arange(0, mid)
        post_idx = np.arange(mid, len(t))

    pre_idx = pre_idx[-pre_len:]
    post_idx = post_idx[:post_len]
    X_pre = X[pre_idx]
    X_post = X[post_idx]

    med = np.median(X_pre, axis=0)
    q75 = np.percentile(X_pre, 75, axis=0)
    q25 = np.percentile(X_pre, 25, axis=0)
    iqr = q75 - q25
    iqr = np.where(iqr <= 1e-6, 1e-6, iqr)

    dev = np.abs(X_post - med[None, :]) / iqr[None, :]
    score = np.max(dev, axis=0)
    metric_order = np.argsort(-score)

    ranked_services = []
    seen = set()
    for j in metric_order:
        svc = metric_to_service(metric_cols[j])
        if svc not in seen:
            ranked_services.append(svc)
            seen.add(svc)

    rank_true = ranked_services.index(true_service) + 1 if true_service in ranked_services else len(ranked_services) + 1
    return rank_true, ranked_services[:10]

def evaluate_baro(summary_df: pd.DataFrame, test_indices, pre_len=300, post_len=300):
    ranks_all = []
    ranks_by_fault = {}
    per_case = []

    for i in tqdm(test_indices, desc="Evaluating BARO"):
        r = summary_df.iloc[i]
        rank_true, top10 = baro_rank_services(
            r["csv_file"], float(r["inject_time"]),
            true_service=r["root_cause_service"],
            pre_len=pre_len, post_len=post_len
        )
        ft = canonical_fault(r["fault_type"])
        ranks_all.append(rank_true)
        ranks_by_fault.setdefault(ft, []).append(rank_true)

        per_case.append({
            "case_id": r["case_id"],
            "fault_type": ft,
            "true_service": r["root_cause_service"],
            "rank_true": rank_true,
            "top10_services": ",".join(top10),
        })

    overall_avg5, overall_ac = avg_at_5_from_ranks(ranks_all)
    row = {
        "method": "BARO_RobustScorer_inject",
        "window_pre": pre_len,
        "window_post": post_len,
        "Avg@5_overall": overall_avg5,
        "AC@1": overall_ac[0], "AC@2": overall_ac[1], "AC@3": overall_ac[2], "AC@4": overall_ac[3], "AC@5": overall_ac[4],
    }
    for k in ["CPU","MEM","DISK","DELAY","LOSS"]:
        row[f"Avg@5_{k}"] = avg_at_5_from_ranks(ranks_by_fault[k])[0] if k in ranks_by_fault else float("nan")

    return pd.DataFrame([row]), pd.DataFrame(per_case)

baro_summary_df, pred_df_baro = evaluate_baro(summary, test_idx, pre_len=PRE_LEN, post_len=POST_LEN)
print("\n=== BARO test summary ===")
print(baro_summary_df.T)

# ------------------------------------------------------------
# (11) Comparison table
# ------------------------------------------------------------
compare_df = pd.concat([
    baro_summary_df[["method","Avg@5_overall","AC@1","AC@2","AC@3","AC@4","AC@5","Avg@5_CPU","Avg@5_MEM","Avg@5_DISK","Avg@5_DELAY","Avg@5_LOSS"]],
    summary_df_st[["method","Avg@5_overall","AC@1","AC@2","AC@3","AC@4","AC@5","Avg@5_CPU","Avg@5_MEM","Avg@5_DISK","Avg@5_DELAY","Avg@5_LOSS"]],
], ignore_index=True)

print("\n=== BARO vs Hierarchical ST (same split) ===")
display(compare_df)

# ------------------------------------------------------------
# (12) Save results + download zip
# ------------------------------------------------------------
out_root = Path("/content/hierarchical_st_vs_baro_outputs")
out_root.mkdir(parents=True, exist_ok=True)

# Save hierarchical ST outputs
st_dir = out_root / "hierarchical_set_transformer"
st_dir.mkdir(parents=True, exist_ok=True)
summary_df_st.to_csv(st_dir / "hier_st_summary.csv", index=False)
pred_df_st.to_csv(st_dir / "hier_st_test_predictions.csv", index=False)
log_df_st.to_csv(st_dir / "hier_st_training_log.csv", index=False)

# Save BARO outputs
baro_dir = out_root / "baro"
baro_dir.mkdir(parents=True, exist_ok=True)
baro_summary_df.to_csv(baro_dir / "baro_summary.csv", index=False)
pred_df_baro.to_csv(baro_dir / "baro_test_predictions.csv", index=False)

# Save comparison
compare_df.to_csv(out_root / "comparison_table.csv", index=False)

# Save metric->group mapping for debugging
map_df = pd.DataFrame({
    "metric_col": metric_cols_ref,
    "group": [svc_groups[g] for g in metric2group]
})
map_df.to_csv(out_root / "metric_to_group_mapping.csv", index=False)

# Zip everything
zip_path = Path("/content/hierarchical_st_vs_baro_ALL.zip")
with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as z:
    for p in out_root.rglob("*"):
        if p.is_file():
            z.write(p, arcname=str(p.relative_to(out_root)))

print("\nSaved all outputs to:", out_root)
files.download(str(zip_path))
